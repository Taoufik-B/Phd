---
Reference ID: A unique identifier for each entry.
Title: Title of the paper/article/book
Authors: Authors of the work.
Year: Year of publication.
Source: Journal name, conference, or publisher.
Keywords:
  - Keywords relevant to your research.
  - this is another row
Methodology: The methodology used in the paper (experimental, review, simulation, etc.).
Summary: Your brief summary of the paper.
Link/DOI: Direct link or DOI for quick access.
Cited By: How many times it has been cited (you can get this from Google Scholar, for instance). It helps in identifying influential papers.
Relevance: High/Medium/Low
tags:
  - "#research/paper"
  - research/communication
File Path/Link: If you have a digital copy, link to its location on your drive for quick access.
Date Reviewed: 
Status: Open/In Progress/Done
---


## Reflections/Notes

**Key Objectives/Questions:**
Example: To explore the challenges and opportunities of implementing POMDPs in real-world multi-agent driving scenarios.

**Main Findings/Results:**
1. POMDPs present challenges in multi-agent environments due to X, Y, Z.
2. Proposed solution A improved computational efficiency by 20%.  

**Methodologies Used:**
Example: The authors used a hybrid approach combining traditional POMDPs with a new algorithm for faster computation.

**Relevance to My Research:**
Example: This paper's approach to improving computational efficiency in POMDPs can be beneficial for my own work on real-time decision making in autonomous vehicles.

**Key Quotations:**
Example: "Our findings suggest that while traditional POMDPs struggle in complex environments, hybrid solutions present a promising direction for future research."

**Personal Reflections/Thoughts:**
Example: While the paper presented a novel approach, there are still some questions about the scalability of their proposed solution. It would be interesting to experiment with their algorithm in a more diverse set of scenarios.
  

## Actionable Next Steps:

Task list:
1. [ ] Replicate the hybrid algorithm discussed in the paper.
2. [ ] Compare its efficiency with the current model I'm working on.


|   |   |
|---|---|
|**Connected papers**|[https://www.connectedpapers.com/main/05e6ac64082df482c32ca0476ba451f6eedb8adc/Multi%20Tree-Guided-Efficient-Robot-Motion-Planning/graph](https://www.connectedpapers.com/main/05e6ac64082df482c32ca0476ba451f6eedb8adc/Multi%20Tree-Guided-Efficient-Robot-Motion-Planning/graph)|
|**MindManager Link**|[Multi-Tree Guided Efficient Robot Motion Planning](http://mj-map://C:/Users/Taoufik/OneDrive/00_PHD/Dashboard.mmap#oid={48A777C0-8C78-4D6A-8AF0-D527DA0B14D2})|
|**File Link**|LINK|
|**Article Note Link**|[Trajectory based lateral control: A Reinforcement Learning case study](Trajectory%20based%20lateral%20control%20A%20Reinforcement%20Learning%20case%20study.md)|
|Arxiv|[Zhirui Sun](https://arxiv.org/search/cs?searchtype=author&query=Sun%2C+Z), [Jiankun Wang](https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+J), [Max Q.-H. Meng](https://arxiv.org/search/cs?searchtype=author&query=Meng%2C+M+Q)<br><br>==Motion Planning is necessary for robots to complete different tasks. Rapidly-exploring Random Tree (RRT) and its variants have been widely used in robot motion planning due to their fast search in state space. However, they perform not well in many complex environments since the motion planning needs to simultaneously consider the geometry constraints and differential constraints. In this article, we propose a novel robot motion planning algorithm that utilizes multi-tree to guide the exploration and exploitation. The proposed algorithm maintains more than two trees to search the state space at first. Each tree will explore the local environment. The tree starts from the root will gradually collect information from other trees and grow towards the goal state. This simultaneous exploration and exploitation method can quickly find a feasible trajectory. We compare the proposed algorithm with other popular motion planning algorithms. The experiment results demonstrate that our algorithm achieves the best performance on different evaluation metrics.==<br><br>\|   \|   \|<br>\|---\|---\|<br>\|Subjects:\|**Robotics (cs.RO)**\|<br>\|Cite as:\|[arXiv:2205.04847](https://arxiv.org/abs/2205.04847) **[cs.RO]**\|<br>\|(or [arXiv:2205.04847v2](https://arxiv.org/abs/2205.04847v2) **[cs.RO]** for this version)\|<br>\|[https://doi.org/10.48550/arXiv.2205.04847](https://doi.org/10.48550/arXiv.2205.04847)<br><br>Focus to learn more\|<br><br>  <br>> From <[https://arxiv.org/abs/2205.04847](https://arxiv.org/abs/2205.04847)>|